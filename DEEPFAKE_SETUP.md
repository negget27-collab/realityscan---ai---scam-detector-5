# üß† Setup Deepfake Detector (EfficientNet B7) ‚Äì RealityScan

Este guia descreve as **etapas manuais** para ativar o detector de deepfake em v√≠deos, usando EfficientNet B7 (modelo selimsef/dfdc_deepfake_challenge) rodando em RunPod ou Cloud Run.

---

## ‚úÖ √öltima etapa manual (quando quiser ativar o GPU)

O sistema EfficientNet j√° est√° **reintegrado e preparado** no c√≥digo. Para ativar:

1. **RunPod:** criar pod GPU (RTX 3090/A5000, PyTorch, Ubuntu 22.04) e abrir o terminal.
2. **No pod:** clonar o repo (ou enviar a pasta `deepfake-api`), depois:
   ```bash
   cd deepfake-api
   chmod +x run_setup.sh && ./run_setup.sh
   export DFDC_DIR=/app/dfdc_deepfake_challenge
   export WEIGHTS_DIR=/app/weights
   python app.py
   ```
3. **RunPod:** mapear porta 8000 (TCP Port Mappings) e copiar a URL p√∫blica (ex: `https://xxxx-8000.proxy.runpod.net`).
4. **No projeto:** no `.env.local` na raiz do RealityScan:
   ```env
   DEEPFAKE_API_URL=https://SUA_URL_RUNPOD
   ```
5. Reiniciar o backend. No log deve aparecer: `‚úî Deepfake API acess√≠vel em ...`.

A partir da√≠: **upload de v√≠deo** e **Sentry** passam a usar EfficientNet B7 (e, no mesmo servidor, wav2vec2 para voz e SyncNet para lip-sync).

---

## ‚ùå Resolver erro "Deepfake API 404: Not Found"

Se o backend mostrar **Deepfake API 404** ou **Deepfake API inacess√≠vel**, a URL em `DEEPFAKE_API_URL` n√£o est√° a responder. Duas formas de resolver:

### Op√ß√£o A ‚Äì API local (recomendado para desenvolvimento)

1. **Subir a Deepfake API em Docker (CPU)** ‚Äî na raiz do projeto:
   ```bash
   npm run deepfake:up
   ```
   Na primeira vez o build pode demorar alguns minutos (download de modelos).

2. **Apontar o backend para a API local** ‚Äî no `.env.local`:
   ```env
   DEEPFAKE_API_URL=http://localhost:8000
   ```

3. **Reiniciar o backend** (`npm run dev:full`). Deve aparecer: `‚úî Deepfake API acess√≠vel em http://localhost:8000`.

Para parar a API local: `npm run deepfake:down`.

### Op√ß√£o B ‚Äì RunPod

Se preferir usar RunPod: confirme que o pod est√° **Running**, que a API est√° a correr no pod (`python app.py` ou via Docker na porta 8000) e que em `.env.local` est√° a **URL atual** do proxy RunPod (a URL muda se o pod for reiniciado). Ver sec√ß√£o "Etapas manuais" abaixo.

---

## Arquitetura

### V√≠deo (upload direto)
```
Usu√°rio clica "analisar v√≠deo"
        ‚Üì
App envia v√≠deo ‚Üí POST /api/scan (multipart)
        ‚Üì
server.js detecta tipo video/* ‚Üí chama DEEPFAKE_API_URL/analisar
        ‚Üì
RunPod: extrai 32 frames ‚Üí EfficientNet B7 ‚Üí score fake 0-1
        ‚Üì
Retorna resultado ao app
```

### Sentry Mini HUD (precis√£o total: visual + voz + lip-sync)
```
Usu√°rio compartilha tela (com √°udio) ‚Üí Sentry captura 3 frames + √°udio
        ‚Üì
POST /api/scan com type=sentry, imagens[], audio (base64)
        ‚Üì
server.js em paralelo:
  ‚Ä¢ EfficientNet B7 (analisar-frames) ‚Üí an√°lise principal visual (1 ou mais frames)
  ‚Ä¢ wav2vec2 (analisar-audio-base64) ‚Üí voz sint√©tica
  ‚Ä¢ SyncNet (analisar-lipsync-sentry) ‚Üí lip-sync boca/√°udio (2+ frames + √°udio)
  ‚Ä¢ Agentes de texto (Gemini/etc.) ‚Üí contexto e s√≠ntese
        ‚Üì
Merge: risco final = max(agentes, EfficientNet, voz, lip-sync); EfficientNet √© refer√™ncia prim√°ria para risco visual.
        ‚Üì
Resultado n√≠vel empresa
```

> **M√≥dulos:** EfficientNet B7 (visual), wav2vec2 (voz sint√©tica), SyncNet (lip-sync). Tudo roda no mesmo servidor GPU.

---

## Etapas manuais

**Checklist:** 1) Conta RunPod + pagamento ‚Üí 2) Deploy GPU Pod (RTX 3090/A5000, PyTorch, Ubuntu 22.04) ‚Üí 3) No terminal: clonar repo (ou upload `deepfake-api`) e rodar `./run_setup.sh` ‚Üí 4) Iniciar API (`python app.py`) ‚Üí 5) Expor porta 8000 e copiar URL ‚Üí 6) Colocar URL em `DEEPFAKE_API_URL` no `.env.local`.

---

### 1. Criar conta RunPod
- Acesse [https://runpod.io](https://runpod.io)
- Crie conta e adicione forma de pagamento

### 2. Deploy do pod GPU
- Deploy ‚Üí GPU Pod
- GPU sugerida: **RTX 3090** ou **A5000** (‚âà $0.20‚Äì0.50/hora)
- Template: **PyTorch** (ou Docker + Python 3.10+)
- Sistema: Ubuntu 22.04

### 3. Instalar ambiente no servidor
No terminal do RunPod (ap√≥s o pod estar ativo):

**Op√ß√£o A ‚Äì Com reposit√≥rio no GitHub**

1. Envie o projeto RealityScan para um reposit√≥rio no GitHub (se ainda n√£o tiver).
2. No terminal do RunPod:

```bash
cd /workspace   # ou /app
# Substitua pela URL do seu reposit√≥rio (ex: https://github.com/SEU_USUARIO/realityscan-ai-scam-detector.git)
git clone https://github.com/SEU_USUARIO/SEU_REPO.git realityscan
cd realityscan/deepfake-api

chmod +x run_setup.sh
./run_setup.sh
```

**Op√ß√£o B ‚Äì Sem GitHub (s√≥ pasta deepfake-api)**

Se voc√™ tiver s√≥ a pasta `deepfake-api` (zip ou upload):

```bash
cd /workspace
# Crie a pasta e coloque app.py, run_setup.sh, requirements.txt aqui (upload ou unzip)
mkdir -p realityscan/deepfake-api
# Depois de colocar os arquivos:
cd realityscan/deepfake-api
chmod +x run_setup.sh
./run_setup.sh
```

Se preferir manual:

```bash
# Clone dfdc_deepfake_challenge
git clone --depth 1 https://github.com/selimsef/dfdc_deepfake_challenge.git /app/dfdc_deepfake_challenge

# Pesos EfficientNet B7 (1 modelo para come√ßar)
mkdir -p /app/weights
cd /app/weights
wget -O final_111_DeepFakeClassifier_tf_efficientnet_b7_ns_0_36 \
  https://github.com/selimsef/dfdc_deepfake_challenge/releases/download/0.0.1/final_111_DeepFakeClassifier_tf_efficientnet_b7_ns_0_36

# Deps Python (visual + voz + lip-sync)
pip install fastapi uvicorn python-multipart torch torchvision opencv-python-headless numpy Pillow albumentations facenet-pytorch timm pandas transformers torchaudio librosa soundfile scenedetect scipy

# SyncNet (lip-sync) - opcional
git clone --depth 1 https://github.com/joonson/syncnet_python.git /app/syncnet_python
cd /app/syncnet_python && bash download_model.sh 2>/dev/null || true

# ffmpeg (necess√°rio para mesclar v√≠deo+√°udio no lip-sync)
# RunPod/Ubuntu: sudo apt-get install -y ffmpeg
```

### 4. Iniciar a API
No mesmo terminal (ajuste o caminho se usou `/workspace` em vez de `/app`):

```bash
cd /workspace/realityscan/deepfake-api   # ou /app/realityscan/deepfake-api
export DFDC_DIR=/app/dfdc_deepfake_challenge
export WEIGHTS_DIR=/app/weights
python app.py
# ou: uvicorn app:app --host 0.0.0.0 --port 8000
```

### 5. Expor a URL (RunPod)
- RunPod: Settings ‚Üí TCP Port Mappings ‚Üí mapear porta 8000
- Copiar a URL p√∫blica (ex: `https://xxxx-8000.proxy.runpod.net`)

### 6. Configurar o servidor Node (RealityScan)
No `.env.local` do projeto (na raiz do app):

```env
DEEPFAKE_API_URL=https://SUA_URL_RUNPOD
```

Exemplo:

```env
DEEPFAKE_API_URL=https://abc123-8000.proxy.runpod.net
```

> ‚ö†Ô∏è Use s√≥ a URL base, sem `/analisar`; o c√≥digo adiciona `/analisar` automaticamente.

### 7. Reiniciar o servidor
```bash
npm run server
# ou
npm run start
```

---

## Vari√°veis de ambiente

| Vari√°vel | Onde | Descri√ß√£o |
|----------|------|-----------|
| `DEEPFAKE_API_URL` ou `VOICE_API_URL` | server.js (.env.local) | URL base da API (RunPod ou Cloud Run). Voice/Lipsync usam a mesma URL. |
| `DFDC_DIR` | deepfake-api (RunPod) | Caminho do clone dfdc_deepfake_challenge |
| `WEIGHTS_DIR` | deepfake-api (RunPod) | Pasta dos pesos `.pth` |
| `MODEL_FILES` | deepfake-api (opcional) | Lista de modelos (v√≠rgula). Default: 1 modelo |

---

## Teste r√°pido

```bash
# Health
curl https://SUA_URL/health

# Analisar v√≠deo
curl -X POST -F "video=@meu_video.mp4" https://SUA_URL/analisar

# Sentry: analisar frames (base64)
curl -X POST -H "Content-Type: application/json" -d '{"frames":["data:image/jpeg;base64,..."]}' https://SUA_URL/analisar-frames
```

Resposta esperada:
```json
{
  "fake": 0.23,
  "real": 0.77,
  "resultado": "aparenta ser conte√∫do real",
  "score_fake_pct": 23.0
}
```

---

## Custo estimado (RunPod)

- GPU RTX 3090: ‚âà $0.24/hora
- Com uso sob clique: ‚âà $20‚Äì60/m√™s
- Gemini (fallback): conforme uso existente

---

## Alternativa: Cloud Run + GPU

1. Dockerfile em `deepfake-api/` (usar base PyTorch GPU)
2. `gcloud run deploy` com `--accelerator type=nvidia-tesla-t4`
3. Usar a URL do Cloud Run em `DEEPFAKE_API_URL`

---

## Troubleshooting

| Problema | Solu√ß√£o |
|----------|---------|
| `WEIGHTS_DIR n√£o encontrado` | Rodar `run_setup.sh` ou baixar pesos manualmente |
| `CUDA out of memory` | Reduzir batch ou usar GPU maior |
| Timeout 2 min | V√≠deo muito longo; limite recomendado ~60s |
| Voice/Lipsync falha | Instalar transformers, torchaudio, librosa; ffmpeg para lip-sync |
| `DEEPFAKE_API_URL n√£o configurada` | Adicionar no `.env.local` e reiniciar o server |

---

## üìã Lista resumida de etapas manuais

1. **RunPod** ‚Äì Criar conta e adicionar pagamento  
2. **RunPod** ‚Äì Deploy GPU Pod (RTX 3090 ou A5000, PyTorch template)  
3. **RunPod** ‚Äì Executar `./run_setup.sh` na pasta `deepfake-api` ou rodar comandos manuais do passo 3  
4. **RunPod** ‚Äì Iniciar a API: `DFDCDIR=... WEIGHTS_DIR=... python app.py`  
5. **RunPod** ‚Äì Configurar mapeamento da porta 8000 e obter URL p√∫blica  
6. **Projeto** ‚Äì Adicionar `DEEPFAKE_API_URL=https://sua-url-runpod` em `.env.local`  
7. **Projeto** ‚Äì Reiniciar o servidor Node (`npm run server` ou `npm start`)
